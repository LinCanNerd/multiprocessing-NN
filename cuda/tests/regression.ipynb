{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\", cuda_available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, activation):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.activation = activation\n",
    "\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            self.fc_layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        self.output_layer = nn.Linear(prev_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        for fc_layer in self.fc_layers:\n",
    "            x = self.activation(fc_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (20640, 8)\n",
      "Output shape: (20640,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5281/91945156.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "california = fetch_california_housing()\n",
    "X = california.data\n",
    "y = california.target\n",
    "\n",
    "# Create a dataframe with the input and output arrays\n",
    "df = pd.DataFrame(X, columns=california.feature_names)\n",
    "df['Target'] = y\n",
    "# df = df.drop(columns=df.columns[-2])\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "df.to_csv('data.csv', index=False)\n",
    "\n",
    "# Print the shape of the input and output arrays\n",
    "print(\"Input shape:\", X.shape)\n",
    "print(\"Output shape:\", y.shape)\n",
    "# print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Epoch 5/100, Train Loss: 2.8231, Test Loss: 2.4201\n",
      "Epoch 10/100, Train Loss: 2.2540, Test Loss: 2.1145\n",
      "Epoch 15/100, Train Loss: 1.7189, Test Loss: 1.6877\n",
      "Epoch 20/100, Train Loss: 1.4624, Test Loss: 1.4059\n",
      "Epoch 25/100, Train Loss: 1.4224, Test Loss: 1.4274\n",
      "Epoch 30/100, Train Loss: 1.4341, Test Loss: 1.4234\n",
      "Epoch 35/100, Train Loss: 1.4356, Test Loss: 1.4047\n",
      "Epoch 40/100, Train Loss: 1.4175, Test Loss: 1.3750\n",
      "Epoch 45/100, Train Loss: 1.3984, Test Loss: 1.3680\n",
      "Epoch 50/100, Train Loss: 1.3919, Test Loss: 1.3686\n",
      "Epoch 55/100, Train Loss: 1.3889, Test Loss: 1.3583\n",
      "Epoch 60/100, Train Loss: 1.3810, Test Loss: 1.3519\n",
      "Epoch 65/100, Train Loss: 1.3754, Test Loss: 1.3491\n",
      "Epoch 70/100, Train Loss: 1.3716, Test Loss: 1.3429\n",
      "Epoch 75/100, Train Loss: 1.3670, Test Loss: 1.3393\n",
      "Epoch 80/100, Train Loss: 1.3638, Test Loss: 1.3368\n",
      "Epoch 85/100, Train Loss: 1.3607, Test Loss: 1.3338\n",
      "Epoch 90/100, Train Loss: 1.3584, Test Loss: 1.3312\n",
      "Epoch 95/100, Train Loss: 1.3563, Test Loss: 1.3295\n",
      "Epoch 100/100, Train Loss: 1.3548, Test Loss: 1.3283\n",
      "Time difference: 0.9765040874481201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data into PyTorch tensors and move them to the GPU\n",
    "X_train = torch.FloatTensor(X_train).to(device)\n",
    "X_test = torch.FloatTensor(X_test).to(device)\n",
    "y_train = torch.FloatTensor(y_train).to(device)\n",
    "y_test = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "# Define the model architecture and move it to the GPU\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [16,4,16]\n",
    "try:\n",
    "    output_size = y_train.shape[1]\n",
    "except IndexError:\n",
    "    output_size = 1\n",
    "model = MLP(input_size, hidden_sizes, output_size, F.relu).to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Number of epochs\n",
    "n_epochs = 100\n",
    "\n",
    "# Placeholder for losses\n",
    "train_losses = np.zeros(n_epochs)\n",
    "test_losses = np.zeros(n_epochs)\n",
    "\n",
    "# Get the current time before the for loop\n",
    "start_time = time.time()\n",
    "\n",
    "for it in range(n_epochs):\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    # Backward and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Save losses\n",
    "    train_losses[it] = loss.item()\n",
    "\n",
    "    # Test loss\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test)\n",
    "    test_losses[it] = test_loss.item()\n",
    "\n",
    "    if (it + 1) % 5 == 0:\n",
    "        print(f'Epoch {it+1}/{n_epochs}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "# Get the current time after the for loop\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the time difference\n",
    "time_difference = end_time - start_time\n",
    "\n",
    "# Print the time difference\n",
    "print(\"Time difference:\", time_difference)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
