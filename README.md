# multiprocessing-NN
Developed a high-performance Multilayer Perceptron (MLP) neural network framework in C/C++ to facilitate deep learning applications. The project encompasses three core implementations: a serial version for baseline performance analysis, and two parallelized versions designed for high-throughput computing environments. The first parallel version utilizes CUDA, leveraging GPU acceleration to significantly enhance computational efficiency and scalability for large-scale neural network training. The second parallel version employs POSIX Threads (Pthreads) to distribute computation across multiple CPU cores, optimizing resource utilization and performance on multicore systems. This comprehensive project demonstrates a deep understanding of both neural network fundamentals and advanced parallel computing techniques, showcasing the ability to optimize deep learning algorithms for various hardware architectures.
